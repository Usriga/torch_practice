{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0eb2e9",
   "metadata": {},
   "source": [
    "# Verification Code Detection -CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156381c",
   "metadata": {},
   "source": [
    "### 1.dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5260e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from captcha.image import ImageCaptcha\n",
    "\n",
    "data_path = \"../Dataset\"\n",
    "\n",
    "# number\n",
    "number = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "# lower character\n",
    "character = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "# upper character\n",
    "upper_character = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "\n",
    "# Random text generation\n",
    "def random_captcha_text(char_set = number,captcha_size = 4):\n",
    "    captcha_text = []\n",
    "    for i in range(captcha_size):\n",
    "        c = random.choice(char_set)\n",
    "        captcha_text.append(c)\n",
    "    return captcha_text \n",
    "\n",
    "# 随机产生验证码图片\n",
    "def gen_capthcha_text_and_image(m):\n",
    "    image = ImageCaptcha()\n",
    "    captcha_text = random_captcha_text()  # 生成验证码文本串，默认4位\n",
    "    captcha_text = ' '.join(captcha_text)  # 生成标签 [4 3 5 8]\n",
    "\n",
    "    # 保存验证码图片\n",
    "    image.write(captcha_text, \"../Dataset/image/\" + '%.4d' % m + '.jpg')  # 保存图片\n",
    "\n",
    "    # 将标签信息写入\n",
    "    with open(data_path + \"/label.txt\", \"a\") as f:\n",
    "        f.write(captcha_text)\n",
    "        f.writelines(\"\\n\")\n",
    "\n",
    "for m in range(500):\n",
    "    gen_capthcha_text_and_image(m)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907a38c",
   "metadata": {},
   "source": [
    "### 2.convulotion layer & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424c1806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH：1]\n",
      "训练损失为：0.0263t训练精度为：0.1081\n",
      "[EPOCH：2]\n",
      "训练损失为：0.0273t训练精度为：0.1120\n",
      "[EPOCH：3]\n",
      "训练损失为：0.0172t训练精度为：0.1126\n",
      "[EPOCH：4]\n",
      "训练损失为：0.0080t训练精度为：0.1217\n",
      "[EPOCH：5]\n",
      "训练损失为：0.0051t训练精度为：0.1328\n",
      "[EPOCH：6]\n",
      "训练损失为：0.0047t训练精度为：0.1354\n",
      "[EPOCH：7]\n",
      "训练损失为：0.0045t训练精度为：0.1452\n",
      "[EPOCH：8]\n",
      "训练损失为：0.0044t训练精度为：0.1823\n",
      "[EPOCH：9]\n",
      "训练损失为：0.0043t训练精度为：0.1986\n",
      "[EPOCH：10]\n",
      "训练损失为：0.0043t训练精度为：0.1999\n",
      "[EPOCH：11]\n",
      "训练损失为：0.0041t训练精度为：0.2435\n",
      "[EPOCH：12]\n",
      "训练损失为：0.0041t训练精度为：0.2520\n",
      "[EPOCH：13]\n",
      "训练损失为：0.0040t训练精度为：0.2741\n",
      "[EPOCH：14]\n",
      "训练损失为：0.0039t训练精度为：0.3118\n",
      "[EPOCH：15]\n",
      "训练损失为：0.0039t训练精度为：0.3177\n",
      "[EPOCH：16]\n",
      "训练损失为：0.0038t训练精度为：0.3307\n",
      "[EPOCH：17]\n",
      "训练损失为：0.0037t训练精度为：0.3730\n",
      "[EPOCH：18]\n",
      "训练损失为：0.0035t训练精度为：0.4134\n",
      "[EPOCH：19]\n",
      "训练损失为：0.0033t训练精度为：0.4570\n",
      "[EPOCH：20]\n",
      "训练损失为：0.0032t训练精度为：0.4798\n",
      "[EPOCH：21]\n",
      "训练损失为：0.0030t训练精度为：0.5052\n",
      "[EPOCH：22]\n",
      "训练损失为：0.0028t训练精度为：0.5456\n",
      "[EPOCH：23]\n",
      "训练损失为：0.0026t训练精度为：0.5781\n",
      "[EPOCH：24]\n",
      "训练损失为：0.0024t训练精度为：0.6315\n",
      "[EPOCH：25]\n",
      "训练损失为：0.0022t训练精度为：0.6693\n",
      "[EPOCH：26]\n",
      "训练损失为：0.0020t训练精度为：0.7005\n",
      "[EPOCH：27]\n",
      "训练损失为：0.0019t训练精度为：0.7188\n",
      "[EPOCH：28]\n",
      "训练损失为：0.0016t训练精度为：0.7591\n",
      "[EPOCH：29]\n",
      "训练损失为：0.0014t训练精度为：0.7962\n",
      "[EPOCH：30]\n",
      "训练损失为：0.0012t训练精度为：0.8327\n",
      "[EPOCH：31]\n",
      "训练损失为：0.0011t训练精度为：0.8529\n",
      "[EPOCH：32]\n",
      "训练损失为：0.0008t训练精度为：0.9036\n",
      "[EPOCH：33]\n",
      "训练损失为：0.0007t训练精度为：0.9173\n",
      "[EPOCH：34]\n",
      "训练损失为：0.0006t训练精度为：0.9355\n",
      "[EPOCH：35]\n",
      "训练损失为：0.0005t训练精度为：0.9499\n",
      "[EPOCH：36]\n",
      "训练损失为：0.0004t训练精度为：0.9648\n",
      "[EPOCH：37]\n",
      "训练损失为：0.0003t训练精度为：0.9779\n",
      "[EPOCH：38]\n",
      "训练损失为：0.0002t训练精度为：0.9876\n",
      "[EPOCH：39]\n",
      "训练损失为：0.0002t训练精度为：0.9961\n",
      "[EPOCH：40]\n",
      "训练损失为：0.0001t训练精度为：0.9941\n",
      "[EPOCH：41]\n",
      "训练损失为：0.0001t训练精度为：0.9980\n",
      "[EPOCH：42]\n",
      "训练损失为：0.0001t训练精度为：0.9987\n",
      "[EPOCH：43]\n",
      "训练损失为：0.0001t训练精度为：0.9987\n",
      "[EPOCH：44]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：45]\n",
      "训练损失为：0.0000t训练精度为：0.9993\n",
      "[EPOCH：46]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：47]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：48]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：49]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：50]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：51]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：52]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：53]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：54]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：55]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：56]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：57]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：58]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：59]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：60]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：61]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：62]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：63]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：64]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：65]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：66]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：67]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：68]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：69]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：70]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：71]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：72]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：73]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：74]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：75]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：76]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：77]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：78]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：79]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：80]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：81]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：82]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：83]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：84]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：85]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：86]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：87]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：88]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：89]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：90]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：91]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：92]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：93]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：94]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：95]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：96]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：97]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：98]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：99]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[EPOCH：100]\n",
      "训练损失为：0.0000t训练精度为：1.0000\n",
      "[finish training]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "import datetime\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,root_dir,label_file,transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.label = np.loadtxt(label_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_name = os.path.join(self.root_dir,'%.4d.jpg' % idx)\n",
    "        image = Image.open(img_name)\n",
    "        labels = self.label[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.label.shape[0])\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3,32,kernel_size=4,stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(32,64,kernel_size=4,stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2,inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  \n",
    "        )\n",
    "        self.fc1 = nn.Linear(64*7*20,512)\n",
    "        self.fc2 = nn.Linear(512,40)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.leaky_relu(x,0.2)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def loss_function(output,label):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    output = output.contiguous().view(-1,10)\n",
    "    label = label.contiguous().view(-1)\n",
    "\n",
    "    total_loss = loss(output,label)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def open_log_file(file_name = None):\n",
    "    file = open('../Result/'+ file_name,'w',encoding = 'utf-8')\n",
    "    return file\n",
    "\n",
    "def close_log_file(file=None):\n",
    "    file.close()\n",
    "\n",
    "def log(msg='',file=None,print_msg=True,end='\\n'):\n",
    "    if print_msg:\n",
    "        print(msg)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    t=str(now.year)+'/'+str(now.month)+'/'+str(now.day)+' '+str(now.hour).zfill(2)+':'+str(now.minute).zfill(2)+':'+str(now.second).zfill(2)\n",
    "    \n",
    "    if isinstance(msg,str):\n",
    "        lines = msg.split('\\n')\n",
    "    else:\n",
    "        lines = [msg]\n",
    "\n",
    "    for line in lines:\n",
    "        if line ==lines[-1]:\n",
    "            file.write('['+t+']'+str(line)+end)\n",
    "        else:\n",
    "            file.write('['+t+']'+str(line))\n",
    "\n",
    "file_path = \"../Dataset/image/\"\n",
    "label_path = \"../Dataset/label.txt\"\n",
    "model_path = \"../model/checkpoint/best_model.pkl\"\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "learning_rate = 0.003\n",
    "\n",
    "dataset = MyDataset(file_path,label_path,transform=transforms.ToTensor())\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "model = ConvNet()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "best_model = model.state_dict()\n",
    "best_acc = 0.0\n",
    "\n",
    "file = open_log_file(file_name='ConvNet')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_acc=0\n",
    "    epoch_count=0\n",
    "    epoch_loss=0\n",
    "\n",
    "    if epoch == 0:\n",
    "        log('[模型结构]',file,False)\n",
    "        log(model,file,False)\n",
    "    \n",
    "    for x,y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_function(pred,y.long())\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_count += pred.contiguous().view(-1,10).argmax(axis = 1).eq(y.contiguous().view(-1)).sum().item()\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_acc = epoch_count / (len(y)*4*3)\n",
    "    epoch_loss /= len(y)*4*3\n",
    "\n",
    "    log(\"[EPOCH：%s]\"%str(epoch+1),file,True)\n",
    "    log(\"训练损失为：{:.4f}\".format(epoch_loss)+'t'+\"训练精度为：{:.4f}\".format(epoch_acc),file,True)\n",
    "\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model = model.state_dict()\n",
    "\n",
    "    if epoch == epochs-1:\n",
    "        torch.save(best_model,model_path)\n",
    "\n",
    "print(\"[finish training]\")  \n",
    "\n",
    "close_log_file(file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee3fe0a",
   "metadata": {},
   "source": [
    "### 3.predict label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1cb5e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证码:  [7, 9, 7, 3]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "img_path = r'../Dataset/image/0457.jpg' # 测试验证码图片\n",
    "\n",
    "img = Image.open(img_path) # 打开图片\n",
    "img = transforms.ToTensor()(img) # 将其转换成tensor\n",
    "img = torch.unsqueeze(img, dim=0) # 处理成模型输入格式 [batch_size, 3, 60, 160]\n",
    "\n",
    "# 自定义卷积网络模型\n",
    "class ConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=1, padding=2),  # 验证码的大小为 [3, 60, 160]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # [batch_size, 32, 30, 80]\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),  # [batch_size, 64, 15, 40]\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2)  # [batch_size, 64, 7, 20]\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 20, 512)\n",
    "        self.fc2 = nn.Linear(512, 40)  # 每个图片中有4个数字，每个数字为10分类，所以为40个输出\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 使用卷积提取特征\n",
    "        x = self.conv(x) # [batch_size, 64, 7, 20]\n",
    "        \n",
    "        # 将特征图拉伸\n",
    "        x = x.view(x.size(0), -1)  # [batch_size, 64 * 7 * 30] 或 [batch_size, 8960]\n",
    "        \n",
    "        # 使用输出层进行分类\n",
    "        x = self.fc1(x) # [batch_size, 512]\n",
    "        x = F.leaky_relu(x, 0.2)\n",
    "        x = self.fc2(x) # [batch_size, 40]\n",
    "\n",
    "        return x\n",
    "\n",
    "# 加载模型权重\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load('../model/checkpoint/best_model.pkl'))\n",
    "\n",
    "\n",
    "# 验证码识别\n",
    "pred = model(img)\n",
    "predict_captcha = pred.contiguous().view(-1, 10).argmax(axis=1).numpy().tolist()\n",
    "print('验证码: ', predict_captcha)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
